* Notes
** Architecture
1. Take in Cifar-10 Dataset
2. Apply transformations to batch 
3. Optionally apply gaussian preprocessing to batch
4. Select the optimizer
5. Do k times:
   1. Train for 1 epoch with the optimizer
   2. Test the model:
      - If ADV training, compute the adv examples and train on it
      - Compute the accuracy on Low Fourier-filtered images on the test dataset
      - Compute the accuracy on High Fourier-filtered images on the test dataset
      - Compute the accuracy on the original images from the test dataset
   3. Save the results into a dict
6. Save the experiment results
* Features
- [ ] ADV training 
- [X] Gaussian Augmentation
- [X] Regular training
* DONE code
** DONE Interfaces
- [X] Create interfaces for moving parts
** DONE Building blocks
- [X] Build Dataset (Cifar10) class
  - [X] ~download_dataset~ method
  - [X] ~load_dataset~ method
  - [X] ~save_datasset~ method
  - [X] ~split_train_test~ method
  - [X] +~apply_transformation~ method+
  - [X] ~apply_gaussian~ method
  - [X] +~generate_adversarial~ method+
  - [X] +~next_batch~ *methods*+
  - [X] Clip and flip for every images
- [X] Build trainer class
  - [X] ~train~ method
  - [X] ~test~ method
  - [X] ~compute_metrics~
* Reading
Readings from the original paper [[https://proceedings.neurips.cc/paper/2019/file/b05b57f6add810d3b7490866d74c0053-Paper.pdf][Fourier perspective]].
1. Section 4.1
1. Section 4.2
2. Section 4.4
* Questions
- Why is the gaussian data augmentation not working ?
- What is the fourrier transform of Gaussian noise? Gaussian noise!
* Other experiments
** DONE Use different seeds and average
** TODO Computing the l_1 norm distribution of the Gaussian augmentations
The plan:
- Sample a few thousand vectors in the shape of the images
- Compute the l_1 norm over these vectors
- Do a few graph, visualization, etc.
** TODO Computing adv trained accuracy
** TODO Overfit model
Why? overfitting = learning not generalizable features. When
overfitting, does it mean we are learningi high frequency features?
** TODO Computing accuracy with a few different bandwidth
The planning:
- For model /i/:
  - For bandwidth /B/:
    1. Compute the fourier transform of the dataset
    2. Apply low frequency pass
    3. Compute accuracy with low frequency passed images
    4. Apply high frequency pass
    5. Compute accuracy with high frequency passed images
  - Save the data:
    - Model
    - Optimizer used
    - High frequency accuracy
    - Low frequency accuracy
    - bandwidth
* Paper
** TODO 
- [ ] Better graphs
- [ ] Params search for SGD (/lr/)
- [ ] Random seeds + a few repetitions
** Fourier perspective main point:
Towards this end, we investigate recently observed tradeoffs caused
by Gaussian data augmentation and adversarial training. We find that
both methods improve robustness to corruptions that are concentrated
in the high frequency domain while reducing robustness to corruptions
that are concentrated in the low frequency domain. *The two*
*augmentation methods encourage the model to become invariant to high*
*frequency information while relying more on low frequency* *information*

** Latex: Planning
*** TODO Introduction
**** DONE Contexte
- [X] done
**** TODO Contenu
- [ ] Include results
**** TODO Conclusion
- [ ] Are the findings similar to original paper?
- [ ] Is it suprising
*** TODO Preliminaries
**** DONE Contexte
- [X] DONE
**** DONE Contenu
- [X] Specify what is shifting freq or not (high/low)
- [X] if ADV: specify the attacks parameters
- [X] Specify the data augmentation used (random flip + crop)
**** DONE Conclusion
- [X] Settings are as similar as possible to the original paper
*** TODO Problem statement and related works
**** TODO Contexte
- [X] Original paper had single architecture + optimizer
- [X] What if their findings are related to arch or optim
**** TODO Contenu
- [X] Bunch of related works + citations
**** TODO Conclusion
- [X] Finish with something like:
  "Here, we try to strenghten (or debunk) the findings from the
  fourier perspective "
*** TODO Experimental protocol
**** TODO Contexte
- [X] Adversarial training is costly
- [ ] Computing the fourier transform of images is costly too
- [ ] if no adv training:
  - We decided to not adv train 
**** TODO Contenu
- [ ] If more experiments, add them here
- [ ] If removing experiments, modify this
- [X] Small paragraph about hyperparameters used during training
- [ ] Modify number of epoch: depends on adv or gaussian
**** TODO Conclusion
- [X] Small paragraph like this:
  "intuitively, this protocol allows us to check if ..."
- [ ] Summary
*** TODO Results
**** TODO Architecture and optimizers
***** TODO Contexte
- [ ] We tried 8 experiments:
  - [ ] 2 optimizer
  - [ ] 2 models
  - [ ] 2 training regimen (is it a word?)
- [ ] 6 seeds for each experiments:
  - [ ] average results are presented.
***** TODO Contenu
- [ ] Suprising results, contradiction to what Fourier perspective
  reported
- [ ] Show graph of reliance on low frequency features:
  - [ ] Explain there is no clear winner, BUT the only noticeably 'better'
    are trained with Adamw.
  - [ ] Gaussian is not better at all
  - [ ] This goes against reported results of Fourier perspective:
    - [ ] Expected gaussian augmentation to have higher reliance than
      others on low freq features
- [ ] Show graph of reliance on high freq features: no obvious pattern
- [ ] Create table proportion of reliance on frequencies!
  - [ ] Show spread on these data points: min max or std ?
- [ ] establish relation between low freq reliance and test accuracy? 
***** TODO Conclusion
- [ ] Our results do not support the results of yinfourier2020.
**** TODO Gaussian augmentation 
***** TODO Contexte
- [ ] The intuitive explanation supporting the use of gaussian data
  augmentation is: Natural images have higher concentrations in low
  frequencies, thus when we refer to a “high” or “low” frequency
  corruption we will always use this term on a relative scale.
  Gaussian noise is uniformly distributed across the Fourier
  frequencies and thus has much higher frequency statistics relative
  to natural images
***** TODO Contenu
- [ ] Gaussian augmentation did not rely more on low frequencies
- [ ] Why?
  - [ ] Gaussian noise is distributed uniformly in the frequency
    domain. Therefore, for a model 'naturally' more relying on low
    frequency features will suffer more when the quality of features
    in the low freq goes down. It learn to be able to use high freq?
    High freq are bigger spectrum, easier less affected by noise *on
    average* (because white noise)
  - [ ] Lower frequencies are more concentrated. Any corruption can be
    felt more harshly
  - [ ] Visualize images of fourier transform (average over cifar test)
  - [ ] Visualize distribution of gaussian noise in fourier transform space
***** TODO Conclusion
- [ ] Gaussian augmentation is no bueno
*** TODO Conclusion
**** TODO Contexte
- [ ] Summary of experiments
- [ ] Their results about gaussian data augmentation bias might be an
  artifact of their model/optimizer.
**** TODO Contenu
- [ ] What we showed
- [ ] How does it compare to the original paper
- [ ] Broader impact
**** TODO Conclusion
- [ ] Limitations
- [ ] Future works
